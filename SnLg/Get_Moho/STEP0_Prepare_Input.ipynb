{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from esdc_inventory import read_esdc_inventory\n",
    "# import glob\n",
    "\n",
    "# resp_file_path1 = r\"/Users/jygong/Stanford/Research_Data/XZ_data_from_Jiangtao/*MSEED/resp/*LH*\"\n",
    "# resp_file_path2 = r\"/Users/jygong/Stanford/Research_Data/XZSeis_250209NewData/*/resp/*LH*\"\n",
    "# resp_file_list = glob.glob(resp_file_path1)\n",
    "# resp_file_list.extend(glob.glob(resp_file_path2))\n",
    "# resp_meta_file = r\"./Inputs/XZ_LH.stations\"\n",
    "\n",
    "# inventory = read_esdc_inventory(resp_meta_file,resp_file_list)\n",
    "\n",
    "# output_file = \"./Inputs/XZ_LH_inventory1.xml\"\n",
    "# inventory.write(output_file, format=\"STATIONXML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 10\n",
      "0 47.3 56.5\n",
      "1 64.1 50.7\n",
      "2 48.3 44.9\n",
      "3 54.0 49.9\n",
      "4 46.7 45.0\n",
      "5 43.9 45.8\n",
      "6 40.4 42.5\n",
      "7 47.7 54.0\n",
      "8 39.1 41.2\n",
      "9 44.6 42.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from interpolate_moho import get_moho, load_gravity_moho_grid, load_rf_moho_grid\n",
    "\n",
    "# ───── CONFIGURATION ─────\n",
    "input_file = \"Tibet.csv\"\n",
    "output_file = \"../Inputs/Tibet.csv\"\n",
    "gravity_mohofile = \"./Moho_Files/GravityMoho.txt\"\n",
    "rf_mohofile = \"./Moho_Files/Moho_RF_int.txt\"\n",
    "apply_depth_filter = True  # Set to False to skip filtering\n",
    "depth_threshold = 0       # Minimum depth (in km) if filtering is applied\n",
    "# ─────────────────────────\n",
    "\n",
    "# ───── Load and rename columns ─────\n",
    "df = pd.read_csv(input_file)\n",
    "df.rename(columns={\n",
    "    'time': 'event_time',\n",
    "    'latitude': 'event_lat',\n",
    "    'longitude': 'event_lon',\n",
    "    'depth': 'event_dep',\n",
    "    'magnitude': 'event_mag',\n",
    "}, inplace=True)\n",
    "\n",
    "# ───── Subset necessary columns ─────\n",
    "columns_to_keep = [\n",
    "    'event_time', 'event_mag', 'event_lat', 'event_lon', 'event_dep',\n",
    "]\n",
    "df_subset = df[columns_to_keep].copy()\n",
    "\n",
    "# ───── Optional depth filter ─────\n",
    "if apply_depth_filter:\n",
    "    df_subset = df_subset[df_subset['event_dep'] > depth_threshold]\n",
    "\n",
    "print(f\"Number of events: {len(df_subset)}\")\n",
    "\n",
    "# ───── Interpolate Moho depth ─────\n",
    "for idx, event in df_subset.iterrows():\n",
    "    evlo = event['event_lon']\n",
    "    evla = event['event_lat']\n",
    "    moho, _ = get_moho(filepath=gravity_mohofile, evlo=evlo, evla=evla, \n",
    "                       load_moho_grid_func=load_gravity_moho_grid, is_plot=False)\n",
    "    df_subset.loc[idx, 'Moho_gravity'] = round(moho,1)  # Round to 1 decimal place\n",
    "    moho_1, _ = get_moho(filepath=rf_mohofile, evlo=evlo, evla=evla, \n",
    "                       load_moho_grid_func=load_rf_moho_grid, is_plot=False)\n",
    "    df_subset.loc[idx, 'Moho_rf'] = round(moho_1,1)  # Round to 1 decimal place\n",
    "    print(idx, round(moho,1),round(moho_1,1))\n",
    "\n",
    "# ───── Save output ─────\n",
    "df_subset.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######## Code that may be useful #########\n",
    "# # Filter the catalog according to time\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # ───── Configuration ─────\n",
    "# input_file = 'XZ_NEIC0_TP.csv'\n",
    "# output_file = 'XZ_NEIC1_TP.csv'\n",
    "# cutoff_date = pd.Timestamp('2009-01-01', tz='UTC')  # UTC-aware cutoff\n",
    "# # ─────────────────────────\n",
    "\n",
    "# # ───── Load and preprocess ─────\n",
    "# cata_df = pd.read_csv(input_file)\n",
    "\n",
    "# # Convert to UTC-aware datetime\n",
    "# cata_df['event_time'] = pd.to_datetime(cata_df['event_time'], utc=True)\n",
    "\n",
    "# # ───── Apply time filter ─────\n",
    "# filtered_df = cata_df[cata_df['event_time'] >= cutoff_date].copy()\n",
    "\n",
    "# # Format to ISO8601 with millisecond precision and trailing 'Z'\n",
    "# filtered_df['event_time'] = (\n",
    "#     filtered_df['event_time']\n",
    "#     .dt.strftime('%Y-%m-%dT%H:%M:%S.%f')\n",
    "#     .str.slice(0, 23) + 'Z'\n",
    "# )\n",
    "\n",
    "# # ───── Output ─────\n",
    "# print(f\"Found {len(filtered_df)} events after {cutoff_date.date()}\")\n",
    "# print(filtered_df)\n",
    "\n",
    "# filtered_df.to_csv(output_file, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthetics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
