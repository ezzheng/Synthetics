{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snlg_analyses import SnLg_Analyses\n",
    "\n",
    "# Define the directory paths\n",
    "BASE_DIRECTORY = './Inputs/'\n",
    "RAW_DIRECTORY = BASE_DIRECTORY + 'raw/'\n",
    "CORRECTED_DIRECTORY = BASE_DIRECTORY + 'corrected/'\n",
    "SELECTED_DIRECTORY = BASE_DIRECTORY + 'selected/'\n",
    "\n",
    "# Initialize class configuration\n",
    "CONFIG = {\n",
    "    \"model\": 'iasp91',   # Make sure the file exists when reading model from user-defined file. Default: 'iasp91'\n",
    "    \"base_directory\": BASE_DIRECTORY,\n",
    "    \"raw_directory\": RAW_DIRECTORY,\n",
    "    \"corrected_directory\": CORRECTED_DIRECTORY,\n",
    "    \"selected_directory\": SELECTED_DIRECTORY,\n",
    "    \"enable_write_sac\": True, \n",
    "    \"enable_archive_waveform\": True,\n",
    "    \"enable_remove_resp\": True,\n",
    "    \"enable_sanity_check\": True,\n",
    "    \"enable_trim_edge\": True,\n",
    "    \"edge_trim_length\": 10,\n",
    "    \"prefilt_window\": (0.05,0.1,10,20),\n",
    "    \"sn_filt\":(0.25, 1.0), # originally 1-4\n",
    "    \"lg_filt\":(0.25, 1.0), # originally 0.5-4\n",
    "    \"enable_zero_phase_filter\": True,\n",
    "    \"min_epi_distance\": 350,\n",
    "    \"max_epi_distance\": 2000,\n",
    "    \"seconds_before_P\": 60,\n",
    "    \"seconds_after_P\": 400,\n",
    "    \"noise_windowlen\": 20,\n",
    "    \"noise_offset\": 5,\n",
    "    \"vsm\": 4.7,\n",
    "    \"vsc\": 3.7,\n",
    "    \"moho_snlg\": 65,\n",
    "    \"snlg_SNR_threshold\": 3,\n",
    "    \"enable_overwrite_log\": True,\n",
    "    \"enable_new_log\"  : False,\n",
    "    \"log_fname\": BASE_DIRECTORY + \"log_iris\",\n",
    "    \"enable_console_output\": False,\n",
    "    \"snlglist_filename\": \"snlg_list_iris\",\n",
    "    \"enable_chunk_list\": True,\n",
    "    \"max_records_before_dump\": 3000\n",
    "}\n",
    "\n",
    "SnLg = SnLg_Analyses(**CONFIG)\n",
    "\n",
    "# Prepare directories\n",
    "SnLg.prepare_directory(SnLg.raw_directory)\n",
    "SnLg.prepare_directory(SnLg.corrected_directory)\n",
    "SnLg.prepare_directory(SnLg.selected_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from obspy.geodetics import kilometers2degrees\n",
    "# A useful function to reduce the number of stations\n",
    "# This function is not perfect, please modify it according to your purpose\n",
    "def select_stations_by_azimuth_distance(\n",
    "    inventory, evla, evlo, max_station=20, n_azimuth_bins=8, n_distance_bins=8\n",
    "):\n",
    "    \"\"\"\n",
    "    Select representative stations using 2D binning by azimuth and distance.\n",
    "    \"\"\"\n",
    "    from obspy.geodetics.base import gps2dist_azimuth\n",
    "    from obspy.core.inventory import Inventory, Network\n",
    "\n",
    "    station_info = []\n",
    "    for network in inventory:\n",
    "        for station in network:\n",
    "            stla = station.latitude\n",
    "            stlo = station.longitude\n",
    "            dist_m, az, _ = gps2dist_azimuth(evla, evlo, stla, stlo)\n",
    "            dist_km = dist_m / 1000\n",
    "            dist_deg = kilometers2degrees(dist_km)\n",
    "            station_info.append({\n",
    "                'network': network.code,\n",
    "                'station': station.code,\n",
    "                'latitude': stla,\n",
    "                'longitude': stlo,\n",
    "                'distance_deg': dist_deg,\n",
    "                'distance_km': dist_km,\n",
    "                'azimuth': az,\n",
    "                'station_obj': station\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(station_info)\n",
    "\n",
    "    # Bin azimuth [0, 360)\n",
    "    df['az_bin'] = pd.cut(df['azimuth'], bins=np.linspace(0, 360, n_azimuth_bins + 1), labels=False, include_lowest=True)\n",
    "\n",
    "    # Bin distance (km)\n",
    "    dist_edges = np.linspace(df['distance_km'].min(), df['distance_km'].max(), n_distance_bins + 1)\n",
    "    df['dist_bin'] = pd.cut(df['distance_km'], bins=dist_edges, labels=False, include_lowest=True)\n",
    "\n",
    "    # Select top 1 station per (az_bin, dist_bin), or more depending on max_station\n",
    "    selected_stations = []\n",
    "    for _, group in df.groupby(['az_bin', 'dist_bin']):\n",
    "        group_sorted = group.sort_values(by='distance_km')\n",
    "        selected_stations.extend(group_sorted.head(1).to_dict('records')) # head(N) -> the first N stations\n",
    "\n",
    "    # Limit to max_station\n",
    "    selected_stations = selected_stations[:max_station]\n",
    "\n",
    "    # Reconstruct a trimmed inventory\n",
    "    new_networks = {}\n",
    "    for s in selected_stations:\n",
    "        net_code = s['network']\n",
    "        if net_code not in new_networks:\n",
    "            new_networks[net_code] = Network(code=net_code, stations=[])\n",
    "        new_networks[net_code].stations.append(s['station_obj'])\n",
    "\n",
    "    return Inventory(networks=list(new_networks.values()), source=inventory.source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.147625620715557 17.986432118374612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n",
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 4.1525 minutes\n"
     ]
    }
   ],
   "source": [
    "from obspy import UTCDateTime\n",
    "from get_seismic_waveforms import get_waveform_from_client\n",
    "from obspy.clients.fdsn import Client\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "MAXIMUM_STATION = 40\n",
    "# client = Client(\"IRIS\")\n",
    "client = Client(\"IRIS\", timeout=60)\n",
    "s_time = time.perf_counter()\n",
    "\n",
    "# Read Inventory and Catalog\n",
    "cata_df = pd.read_csv('./Inputs/Tibet.csv',index_col=False)\n",
    "# print(type(cata_df))\n",
    "\n",
    "min_dis_deg = kilometers2degrees(CONFIG[\"min_epi_distance\"])\n",
    "max_dis_deg = kilometers2degrees(CONFIG[\"max_epi_distance\"])\n",
    "\n",
    "print(min_dis_deg,max_dis_deg)\n",
    "\n",
    "for idx, row in cata_df.iterrows():\n",
    "    # 1) Make a single-event DataFrame\n",
    "    #    The double brackets [[idx]] ensure it's still a DataFrame, not a Series\n",
    "    event_df = cata_df.loc[[idx]]\n",
    "    # 2) Build the per-event inventory.\n",
    "    #    e.g., selecting stations within some radius of this event\n",
    "    # print(row)\n",
    "    evla = row.event_lat\n",
    "    evlo = row.event_lon\n",
    "    starttime = UTCDateTime(row.event_time)\n",
    "    endtime   = starttime + 3600\n",
    "    # print(type(starttime))\n",
    "    # TEST CODE: use BH* stations for simplicity ...\n",
    "    for attempt in range(2):\n",
    "        try:\n",
    "            custom_inventory = client.get_stations(\n",
    "            level='channel',    # level='channel' is nessary for rotating BH[12] -> BH[NE]\n",
    "            starttime=starttime, endtime=endtime,\n",
    "            channel='BH*', network=\"*\", location=\"*\", station=\"*\",\n",
    "            latitude=evla, longitude=evlo,\n",
    "            minradius=min_dis_deg, maxradius=max_dis_deg\n",
    "        )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logger0.info(f\"[Worker {worker_id}] Attempt {attempt+1} failed: {e}\")\n",
    "            time.sleep(1)\n",
    "    else:\n",
    "        continue  # skip this event\n",
    "        \n",
    "    if sum(len(net.stations) for net in custom_inventory) > MAXIMUM_STATION:\n",
    "        custom_inventory = select_stations_by_azimuth_distance(\n",
    "            inventory=custom_inventory,\n",
    "            evla=evla,\n",
    "            evlo=evlo,\n",
    "            max_station=MAXIMUM_STATION,\n",
    "            n_azimuth_bins=8,\n",
    "            n_distance_bins=8\n",
    "        )\n",
    "\n",
    "    # print(custom_inventory)\n",
    "    SnLg.process_snlg_bulk(catalog_dataframe=event_df, inventory=custom_inventory, \n",
    "                  get_seismic_trace_func=get_waveform_from_client,\n",
    "                  client=client,channel_requested='BH*',location_requested=\"*\")\n",
    "    \n",
    "SnLg.output_final_snlg_list()\n",
    "\n",
    "e_time = time.perf_counter()\n",
    "elapsed_time = (e_time - s_time) / 60\n",
    "print(f\"Elapsed time: {elapsed_time:.4f} minutes\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthetics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
